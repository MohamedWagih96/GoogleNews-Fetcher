{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\nltk\\twitter\\__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
      "  warnings.warn(\"The twython library has not been installed. \"\n"
     ]
    }
   ],
   "source": [
    "import requests , nltk , time\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from pandas import DataFrame\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No more pages left!\n"
     ]
    }
   ],
   "source": [
    "keyword = 'strawberry'\n",
    "url = 'https://www.google.com/search?q='+keyword+'&hl=en&source=lnms&tbm=nws&sa=X&ved=0ahUKEwi39q3H_ZjdAhXnMewKHbszDXIQ_AUICygC&biw=1536&bih=728&dpr=1.25'\n",
    "source_list = []\n",
    "date_list = []\n",
    "title_list = []\n",
    "description_list = []\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        #Parse the webpage\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.text , 'html5lib')\n",
    "        \n",
    "        #Grab the Headline\n",
    "        for title in soup.find_all('h3'):\n",
    "            title_list.append(title.text)\n",
    "        \n",
    "        #Grab the Soruce and Date\n",
    "        for sd in soup.find_all('div',{'class':'slp'}):\n",
    "            info = sd.text.split(' - ')\n",
    "            source = info[0]\n",
    "            source_list.append(source)\n",
    "            date = info[len(info)-1]\n",
    "            date_list.append(date)\n",
    "        \n",
    "        #Grab the Description\n",
    "        for desc in soup.find_all('div',{'class':'st'}):\n",
    "            description_list.append(desc.text)\n",
    "        \n",
    "        #Get the next page url\n",
    "        driver.get(url)\n",
    "        driver.find_element_by_link_text('Next').click()\n",
    "        url = driver.current_url\n",
    "        \n",
    "        #Some delay in order to not get blocked [Remove it if you don't have too much pages to review]\n",
    "        time.sleep(30)\n",
    "        \n",
    "    except NoSuchElementException:\n",
    "        print(\"No more pages left!\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSentiment(text):\n",
    "    sentiment = \"\"\n",
    "    ps = analyzer.polarity_scores(text)\n",
    "    \n",
    "    #Positive sentiments\n",
    "    if ps['neg'] <= 0.5 and ps['pos'] > 0:\n",
    "        if ps['pos'] - ps['neg'] >= 0:\n",
    "            sentiment = '1'\n",
    "        elif ps['neu'] >= 0.5:\n",
    "            sentiment = '1'\n",
    "        else:\n",
    "            sentiment = '0'\n",
    "    \n",
    "    #Negative sentiments\n",
    "    elif ps['pos'] <= 0.5 and ps['neg'] > 0:\n",
    "        if ps['neg'] - ps['pos'] >= 0:\n",
    "            sentiment = '0'\n",
    "        elif ps['neu'] <= 0.5:\n",
    "            sentiment = '0'\n",
    "        else:\n",
    "            sentiment = '1'\n",
    "    \n",
    "    else:\n",
    "        sentiment = getSentiment('Good '+ text)\n",
    "    \n",
    "    return sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "x = 'Strawberry cure for painful illnesses'\n",
    "print(analyzer.polarity_scores(x))\n",
    "print(getSentiment(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive News Percentage :  87.5 %\n",
      "Negative News Percentage :  12.5 %\n",
      "Unknowns :  0 sentences ,  0.0 %\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "labels_list = []\n",
    "\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "x = description_list[1]\n",
    "\n",
    "for sentence in title_list:\n",
    "    sentiment = getSentiment(sentence)\n",
    "    if(sentiment == '1' or sentiment == '0'):\n",
    "        labels_list.append(sentiment)\n",
    "    elif(sentiment == '?'):\n",
    "        labels_list.append(getSentiment(description_list[i]))\n",
    "    else:\n",
    "        labels_list.append('?')\n",
    "        \n",
    "    i += 1\n",
    "        \n",
    "print(\"Positive News Percentage : \" , labels_list.count('1')/len(description_list)*100 , \"%\")\n",
    "print(\"Negative News Percentage : \" , labels_list.count('0')/len(description_list)*100 , \"%\")\n",
    "print(\"Unknowns : \" , labels_list.count('?') ,'sentences , ' , labels_list.count('?')/len(description_list)*100 , \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = DataFrame({'Headline': title_list , 'Source': source_list , 'Date/Time': date_list , 'Description': description_list , 'Labels': labels_list})\n",
    "df.to_excel('f.xlsx' , sheet_name = 'sheet1' , index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sentiment_mod'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-cd0f86f58fae>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0msentiment_mod\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sentiment_mod'"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import sentiment_mod as s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()\n",
    "x = 'crops'\n",
    "print(analyzer.polarity_scores(x))\n",
    "print(getSentiment(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
